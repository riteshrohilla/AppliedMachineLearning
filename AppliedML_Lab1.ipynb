{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8af9a4d-72c4-41b4-abe4-ba2d69608780",
   "metadata": {},
   "source": [
    "### Task1 - Wine Quality Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb98318-2675-48ce-bcba-93af652aabac",
   "metadata": {},
   "source": [
    "### Task 2: Data Preprocessing\n",
    "##### 1. Objective: Learn how to preprocess data for machine learning models.\n",
    "##### 2. Description:\n",
    "###### - Load a given dataset.\n",
    "###### - Perform data cleaning (handle missing values, remove duplicates, etc.).\n",
    "###### - Normalize or standardize the data.\n",
    "###### - Split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3337f0fe-1c68-4c8c-87f5-059475ef7b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280a1ae2-6d55-4f7c-a35c-2aec6ef4fd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = '/Users/riteshrohilla/Desktop/wine+quality/winequality-white.csv'\n",
    "try:\n",
    "    data = pd.read_csv(file_path, delimiter=';')\n",
    "    print(\"Dataset loaded successfully\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path.\")\n",
    "except pd.errors.ParserError:\n",
    "    print(\"Error parsing the file. Please check the file format.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf0dd314-e48d-427d-8d1f-e9ba32c98ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         4898 non-null   float64\n",
      " 1   volatile acidity      4898 non-null   float64\n",
      " 2   citric acid           4898 non-null   float64\n",
      " 3   residual sugar        4898 non-null   float64\n",
      " 4   chlorides             4898 non-null   float64\n",
      " 5   free sulfur dioxide   4898 non-null   float64\n",
      " 6   total sulfur dioxide  4898 non-null   float64\n",
      " 7   density               4898 non-null   float64\n",
      " 8   pH                    4898 non-null   float64\n",
      " 9   sulphates             4898 non-null   float64\n",
      " 10  alcohol               4898 non-null   float64\n",
      " 11  quality               4898 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 459.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display initial dataset info\n",
    "print(\"\\nInitial data info:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf33f6d2-a746-4998-a124-ee5df7b7f4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No missing values found.\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "missing_values_count = data.isnull().sum().sum()\n",
    "if missing_values_count > 0:\n",
    "    print(f\"\\nMissing values found: {missing_values_count}\")\n",
    "    data = data.dropna()\n",
    "    print(\"Missing values removed.\")\n",
    "else:\n",
    "    print(\"\\nNo missing values found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "335ce780-9404-4477-bede-a6d6f0f415e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate rows found: 937\n",
      "Duplicate rows removed.\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "duplicate_rows_count = data.duplicated().sum()\n",
    "if duplicate_rows_count > 0:\n",
    "    print(f\"\\nDuplicate rows found: {duplicate_rows_count}\")\n",
    "    data = data.drop_duplicates()\n",
    "    print(\"Duplicate rows removed.\")\n",
    "else:\n",
    "    print(\"\\nNo duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd4580e8-e026-4150-9cf8-cc1148d528f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data normalized successfully\n"
     ]
    }
   ],
   "source": [
    "# Normalize or standardize the data\n",
    "scaler = MinMaxScaler()\n",
    "try:\n",
    "    # Assuming all columns except the target column are numeric for normalization\n",
    "    numeric_columns = data.select_dtypes(include='number').columns\n",
    "    data[numeric_columns] = scaler.fit_transform(data[numeric_columns])\n",
    "    print(\"\\nData normalized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during normalization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "739a939f-f860-46ed-a102-cf109ca53cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training and testing sets successfully\n"
     ]
    }
   ],
   "source": [
    "target_column = 'quality'\n",
    "if target_column in data.columns:\n",
    "    X = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        print(\"Data split into training and testing sets successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during train-test split: {e}\")\n",
    "else:\n",
    "    print(f\"Target column '{target_column}' not found in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25aa6c6-f5db-4dcb-b044-2e9040c402d6",
   "metadata": {},
   "source": [
    "### Task 3: Model Training and Evaluation\n",
    "##### 1. Objective: Train and evaluate a machine learning model.\n",
    "##### 2. Description:\n",
    "###### - Choose a suitable algorithm (e.g., linear regression, decision tree, etc.).\n",
    "###### - Train the model using the training dataset.\n",
    "###### - Evaluate the model's performance using the testing dataset.\n",
    "###### - Report the model's accuracy, precision, recall, and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e841e51d-0678-4b69-979e-b9338139be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fc1b182-0406-4d1e-a30d-b9d305f9f3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset with the correct delimiter\n",
    "file_path = '/Users/riteshrohilla/Desktop/wine+quality/winequality-white.csv'\n",
    "try:\n",
    "    data = pd.read_csv(file_path, delimiter=';')\n",
    "    print(\"Dataset loaded successfully\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path.\")\n",
    "except pd.errors.ParserError:\n",
    "    print(\"Error parsing the file. Please check the file format.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4414b3aa-e167-4a0e-9d8f-ea250edaf5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         4898 non-null   float64\n",
      " 1   volatile acidity      4898 non-null   float64\n",
      " 2   citric acid           4898 non-null   float64\n",
      " 3   residual sugar        4898 non-null   float64\n",
      " 4   chlorides             4898 non-null   float64\n",
      " 5   free sulfur dioxide   4898 non-null   float64\n",
      " 6   total sulfur dioxide  4898 non-null   float64\n",
      " 7   density               4898 non-null   float64\n",
      " 8   pH                    4898 non-null   float64\n",
      " 9   sulphates             4898 non-null   float64\n",
      " 10  alcohol               4898 non-null   float64\n",
      " 11  quality               4898 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 459.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display initial dataset info\n",
    "print(\"Initial data info:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "562886f6-fbd5-4dc7-9a91-68c41703cfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.0              0.27         0.36            20.7      0.045   \n",
      "1            6.3              0.30         0.34             1.6      0.049   \n",
      "2            8.1              0.28         0.40             6.9      0.050   \n",
      "3            7.2              0.23         0.32             8.5      0.058   \n",
      "4            7.2              0.23         0.32             8.5      0.058   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
      "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
      "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
      "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      8.8        6  \n",
      "1      9.5        6  \n",
      "2     10.1        6  \n",
      "3      9.9        6  \n",
      "4      9.9        6  \n"
     ]
    }
   ],
   "source": [
    "# Check the first few rows to ensure correct loading\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abf941fa-614a-472b-bf0e-95fd48a4eb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values found.\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "missing_values_count = data.isnull().sum().sum()\n",
    "if missing_values_count > 0:\n",
    "    print(f\"Missing values found: {missing_values_count}\")\n",
    "    data = data.dropna()\n",
    "    print(\"Missing values removed.\")\n",
    "else:\n",
    "    print(\"No missing values found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e962e477-d97a-40ee-b74f-a92dff6354ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows found: 937\n",
      "Duplicate rows removed.\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "duplicate_rows_count = data.duplicated().sum()\n",
    "if duplicate_rows_count > 0:\n",
    "    print(f\"Duplicate rows found: {duplicate_rows_count}\")\n",
    "    data = data.drop_duplicates()\n",
    "    print(\"Duplicate rows removed.\")\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "899ba38c-d236-4825-8bb6-f0fc335637ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data normalized successfully\n"
     ]
    }
   ],
   "source": [
    "# Normalize the Data\n",
    "scaler = MinMaxScaler()\n",
    "try:\n",
    "    data_normalized = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "    print(\"Data normalized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during normalization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfb669f2-e3b4-4e27-9c40-658f39b0010d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable distribution:\n",
      "quality\n",
      "6    1788\n",
      "5    1175\n",
      "7     689\n",
      "4     153\n",
      "8     131\n",
      "3      20\n",
      "9       5\n",
      "Name: count, dtype: int64\n",
      "Data split into training and testing sets successfully\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'quality' is the name of the column you want to predict\n",
    "target_column = 'quality'\n",
    "if target_column in data.columns:\n",
    "    X = data_normalized.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "\n",
    "    # Convert the target variable to integer categories\n",
    "    y = y.astype(int)\n",
    "    \n",
    "    # Check the distribution of the target variable\n",
    "    print(\"Target variable distribution:\")\n",
    "    print(y.value_counts())\n",
    "\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "        print(\"Data split into training and testing sets successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during train-test split: {e}\")\n",
    "else:\n",
    "    print(f\"Target column '{target_column}' not found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "915b97e0-90e8-4fa2-b91c-af0194b3bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7df28b4d-377b-4293-8ee6-005b3f590e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Model training completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c54787c-c76f-482a-9bcc-eb3b625c19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the testing dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48068002-bea5-4b35-9528-f26a82e1a1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43757881462799497\n",
      "Precision: 0.436958023902114\n",
      "Recall: 0.43757881462799497\n",
      "F1-Score: 0.43596999327010083\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6d9e77e-7fc7-4b71-9d48-119dd7b840fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.25      0.19      0.22        31\n",
      "           5       0.48      0.44      0.46       235\n",
      "           6       0.49      0.52      0.51       358\n",
      "           7       0.32      0.35      0.33       138\n",
      "           8       0.12      0.12      0.12        26\n",
      "           9       1.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.44       793\n",
      "   macro avg       0.38      0.23      0.23       793\n",
      "weighted avg       0.44      0.44      0.44       793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display a detailed classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74120b2c-3ad4-46eb-915c-5bcde489a034",
   "metadata": {},
   "source": [
    "### Task 4: Model Tuning and Optimization\n",
    "##### 1. Objective: Improve the performance of a machine learning model.\n",
    "##### 2. Description:\n",
    "###### - Perform hyperparameter tuning (e.g., grid search, random search).\n",
    "###### - Implement cross-validation to ensure the model's robustness.\n",
    "###### - Compare the performance of the tuned model with the original model.\n",
    "###### - Discuss any improvements or observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d59baf00-8b49-4951-b401-9e39972f4d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7cdfc46-d5d1-49bc-8771-1aff306b0698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = '/Users/riteshrohilla/Desktop/wine+quality/winequality-white.csv'\n",
    "try:\n",
    "    data = pd.read_csv(file_path, delimiter=';')\n",
    "    print(\"Dataset loaded successfully\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path.\")\n",
    "except pd.errors.ParserError:\n",
    "    print(\"Error parsing the file. Please check the file format.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1eb602ab-c3ef-467c-bfbf-e14d7766be9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         4898 non-null   float64\n",
      " 1   volatile acidity      4898 non-null   float64\n",
      " 2   citric acid           4898 non-null   float64\n",
      " 3   residual sugar        4898 non-null   float64\n",
      " 4   chlorides             4898 non-null   float64\n",
      " 5   free sulfur dioxide   4898 non-null   float64\n",
      " 6   total sulfur dioxide  4898 non-null   float64\n",
      " 7   density               4898 non-null   float64\n",
      " 8   pH                    4898 non-null   float64\n",
      " 9   sulphates             4898 non-null   float64\n",
      " 10  alcohol               4898 non-null   float64\n",
      " 11  quality               4898 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 459.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display initial dataset info\n",
    "print(\"\\nInitial data info:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ce567a3-3bc8-43b4-9fed-e5b55e7ca0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No missing values found.\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "missing_values_count = data.isnull().sum().sum()\n",
    "if missing_values_count > 0:\n",
    "    print(f\"\\nMissing values found: {missing_values_count}\")\n",
    "    data = data.dropna()\n",
    "    print(\"Missing values removed.\")\n",
    "else:\n",
    "    print(\"\\nNo missing values found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06862cc4-778d-4d2c-ad6b-7b95631f7af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate rows found: 937\n",
      "Duplicate rows removed.\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "duplicate_rows_count = data.duplicated().sum()\n",
    "if duplicate_rows_count > 0:\n",
    "    print(f\"\\nDuplicate rows found: {duplicate_rows_count}\")\n",
    "    data = data.drop_duplicates()\n",
    "    print(\"Duplicate rows removed.\")\n",
    "else:\n",
    "    print(\"\\nNo duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f51d29dc-8be8-4398-b4a1-3a878e759cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data normalized successfully\n"
     ]
    }
   ],
   "source": [
    "# Normalize the Data\n",
    "scaler = MinMaxScaler()\n",
    "try:\n",
    "    data_normalized = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "    print(\"\\nData normalized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during normalization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5507fa23-c041-44bd-8302-0498c24f70ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable distribution:\n",
      "quality\n",
      "6    1788\n",
      "5    1175\n",
      "7     689\n",
      "4     153\n",
      "8     131\n",
      "3      20\n",
      "9       5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data split into training and testing sets successfully\n"
     ]
    }
   ],
   "source": [
    "# Split data into features (X) and target (y)\n",
    "target_column = 'quality'\n",
    "if target_column in data.columns:\n",
    "    X = data_normalized.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "    \n",
    "    # Convert the target variable to integer categories\n",
    "    y = y.astype(int)\n",
    "    \n",
    "    # Check the distribution of the target variable\n",
    "    print(\"\\nTarget variable distribution:\")\n",
    "    print(y.value_counts())\n",
    "    # Train-test split\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "        print(\"\\nData split into training and testing sets successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn error occurred during train-test split: {e}\")\n",
    "else:\n",
    "    print(f\"\\nTarget column '{target_column}' not found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c64c2868-283b-4d1d-9f32-13b2c7811133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b8dddfb-3590-496a-a474-5a93361b8568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4dcac78d-65ea-4874-9b13-c839535eadf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7, 10],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7, 10],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [3, 5, 7, 10],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform Grid Search with Cross-Validation using StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=skf, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26dd4f0a-a7f2-4df5-b31e-0a995b79759a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Cross-Validation Score: 0.51010101010101\n"
     ]
    }
   ],
   "source": [
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Cross-Validation Score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44c00776-3d99-4125-ab2c-c40cf7a6ede9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned model training completed\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier with the best parameters\n",
    "best_clf = grid_search.best_estimator_\n",
    "best_clf.fit(X_train, y_train)\n",
    "print(\"Tuned model training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb22e67f-01c4-4f80-abdb-163a05ee910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the testing dataset\n",
    "y_pred = best_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8d0ac54-1d0a-4f0b-a88c-b79965708ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5119798234552333\n",
      "Precision: 0.5468505783057205\n",
      "Recall: 0.5119798234552333\n",
      "F1-Score: 0.47463570724819837\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2640b3a1-5943-4b1c-b045-bc101a42ecd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      0.00      0.00         4\n",
      "           4       1.00      0.00      0.00        31\n",
      "           5       0.53      0.63      0.57       235\n",
      "           6       0.51      0.65      0.57       358\n",
      "           7       0.48      0.20      0.28       138\n",
      "           8       1.00      0.00      0.00        26\n",
      "           9       1.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.51       793\n",
      "   macro avg       0.79      0.21      0.20       793\n",
      "weighted avg       0.55      0.51      0.47       793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display a detailed classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cec8e5e-1d1b-4f3f-b5fd-59323bcb0967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
